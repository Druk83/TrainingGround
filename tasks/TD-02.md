# TD-02 — Разделение Python Generator на API и Worker сервисы

## Статус
**Не начато** (создано 23.12.2024)

## Контекст

После завершения задачи A3 (Python Explanation Builder и Embedding Pipeline) выявлена проблема производительности при сборке Docker образа `python-generator`. Текущая монолитная архитектура требует установки тяжелых ML библиотек (sentence-transformers, PyTorch, numpy, scipy) даже для API контейнера, хотя embeddings генерируются только worker процессом.

**Проблема**: Сборка Docker образа занимает **~14 минут** из-за ML зависимостей, что замедляет CI/CD и локальную разработку.

**Решение**: Разделить сервис на два независимых контейнера с разными зависимостями и Dockerfile.

## Текущая архитектура (монолит)

```
┌─────────────────────────────────────────┐
│      python-generator (монолит)        │
│  ┌────────────────────────────────────┐ │
│  │  FastAPI Application               │ │
│  │  - /v1/explanations (YandexGPT)    │ │
│  │  - /v1/rag/* (RAG pipeline)        │ │
│  │  - /health, /metrics               │ │
│  └────────────────────────────────────┘ │
│  ┌────────────────────────────────────┐ │
│  │  EmbeddingWorker (asyncio task)    │ │
│  │  - Redis Stream consumer           │ │
│  │  - sentence-transformers           │ │
│  │  - Qdrant indexing                 │ │
│  └────────────────────────────────────┘ │
│                                         │
│  Зависимости: FastAPI + ML (850 MB)    │
│  Сборка: 14 минут                       │
└─────────────────────────────────────────┘
```

**Проблемы**:
- API не нуждается в ML библиотеках, но вынужден их устанавливать
- При изменении API кода пересобирается весь образ с ML зависимостями
- Невозможно масштабировать API и worker независимо
- Большой размер образа (850 MB вместо ~150 MB для API)

## Целевая архитектура (микросервисы)

```
┌───────────────────────────┐          ┌────────────────────────────┐
│  python-generator-api     │          │  python-generator-worker   │
│  ┌──────────────────────┐ │          │  ┌──────────────────────┐  │
│  │  FastAPI Application │ │          │  │  EmbeddingWorker     │  │
│  │  - /v1/explanations  │ │          │  │  - Redis Stream      │  │
│  │  - /v1/rag/*         │ │          │  │  - Embeddings        │  │
│  │  - /health, /metrics │ │          │  │  - Qdrant sync       │  │
│  └──────────────────────┘ │          │  └──────────────────────┘  │
│                           │          │                            │
│  Зависимости: FastAPI    │          │  Зависимости: FastAPI + ML │
│  Размер: ~150 MB          │  Redis   │  Размер: ~850 MB           │
│  Сборка: 2 минуты         │  Stream  │  Сборка: 14 минут          │
└───────────────────────────┘ ◄──────► └────────────────────────────┘
           │                                      │
           ├──────────────────┬─────────────────┤
           ▼                  ▼                  ▼
     ┌──────────┐      ┌──────────┐      ┌──────────┐
     │ MongoDB  │      │  Redis   │      │ Qdrant   │
     └──────────┘      └──────────┘      └──────────┘
```

**Преимущества**:
- ✅ API собирается за **2 минуты** вместо 14 (изменения кода API)
- ✅ Worker пересобирается только при изменении ML кода (редко)
- ✅ Независимое масштабирование (можно запустить 3 worker + 1 API)
- ✅ Меньше потребление ресурсов (API без PyTorch/CUDA)
- ✅ Связь через Redis Stream (уже реализовано в A3)

## Выявленные проблемы

### Критичные
1. **EmbeddingWorker запускается внутри API** — в `app.py:74-78` worker стартует как asyncio task внутри FastAPI приложения, поэтому ML библиотеки обязательны для API контейнера.
2. **Нет отдельного entrypoint для worker** — отсутствует CLI команда для запуска только worker без FastAPI сервера.
3. **Единый Dockerfile с ML зависимостями** — `backend/python-generator/Dockerfile` устанавливает все зависимости из `pyproject.toml`, включая sentence-transformers.

### Важные
4. **Невозможно масштабировать worker** — нельзя запустить несколько worker реплик для обработки большой очереди embeddings.
5. **API перезапускается при падении worker** — если worker крашится (OOM на больших моделях), падает весь контейнер включая API.
6. **Зависимости не разделены** — `pyproject.toml` содержит единый список dependencies, нет опциональных групп для ML.

## Состав работ

### 1. Разделение зависимостей в pyproject.toml

Создать опциональные группы зависимостей:

**Обновить `backend/python-generator/pyproject.toml`:**

```toml
[project]
dependencies = [
  # API dependencies (без ML)
  "fastapi>=0.115",
  "uvicorn>=0.30",
  "pydantic>=2.9",
  "pydantic-settings>=2.6",
  "httpx>=0.27",
  "motor>=3.5",
  "redis>=7.1.0",
  "qdrant-client>=1.9",  # Нужен для RAG в API
  "prometheus-client>=0.20",
  "apscheduler>=3.10",
  "typer>=0.12",
  "tenacity>=9.0",
  "python-json-logger>=4.0.0"
]

[project.optional-dependencies]
# ML dependencies (только для worker)
worker = [
  "sentence-transformers>=5.2.0",
  "numpy>=2.4.0",
  "scipy>=1.11",
  "pymorphy2>=0.9",
  "natasha>=1.6"
]

dev = [
  "pytest>=9.0.2",
  "pytest-asyncio>=1.3.0",
  "mypy>=1.13",
  "ruff>=0.7",
  "httpx>=0.27",
  "types-redis",
  "types-requests",
  "black>=25.12.0",
  "fakeredis>=2.23"
]

[project.scripts]
explanation-worker = "explanation_service.cli.embeddings:main"
explanation-api = "explanation_service.cli.api:main"  # Новый entrypoint
rebuild-embeddings = "explanation_service.cli.rebuild_embeddings:main"
```

### 2. Создание отдельного entrypoint для API

**Создать `backend/python-generator/src/explanation_service/cli/api.py`:**

```python
"""CLI entrypoint для запуска только API без worker."""

import typer
import uvicorn

app = typer.Typer()


@app.command()
def main(
    host: str = "0.0.0.0",
    port: int = 8000,
    reload: bool = False,
) -> None:
    """Запустить FastAPI сервер без embedding worker."""
    uvicorn.run(
        "explanation_service.app:create_app",
        host=host,
        port=port,
        reload=reload,
        factory=True,
    )


if __name__ == "__main__":
    app()
```

### 3. Рефакторинг app.py для опционального worker

**Обновить `backend/python-generator/src/explanation_service/app.py`:**

```python
import os

def create_app() -> FastAPI:
    settings = get_settings()
    configure_logging(settings.log_level)

    app = FastAPI(...)

    # ... middleware, routes ...

    @app.on_event("startup")
    async def on_startup() -> None:
        # Инициализация клиентов (MongoDB, Redis, Qdrant, YandexGPT)
        # ... существующий код ...

        # Запуск worker только если переменная окружения установлена
        if os.getenv("START_EMBEDDING_WORKER", "false").lower() == "true":
            worker = EmbeddingWorker(
                settings, app.state.mongo_db, redis_client, qdrant_client
            )
            app.state.embedding_worker = worker
            app.state.embedding_task = asyncio.create_task(worker.run_forever())
            logging.getLogger(__name__).info("EmbeddingWorker started")
        else:
            app.state.embedding_worker = None
            app.state.embedding_task = None
            logging.getLogger(__name__).info("EmbeddingWorker disabled")

        # ... остальной код ...

    @app.on_event("shutdown")
    async def on_shutdown() -> None:
        # ... существующий код ...

        # Остановить worker только если он был запущен
        worker_task: asyncio.Task | None = app.state.embedding_task
        if worker_task:
            worker_task.cancel()
            with contextlib.suppress(asyncio.CancelledError):
                await worker_task

        # ... остальной код ...

    return app
```

### 4. Создание Dockerfile для API

**Создать `backend/python-generator/Dockerfile.api`:**

```dockerfile
FROM python:3.11-slim

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

WORKDIR /app

RUN apt-get update \
    && apt-get install -y --no-install-recommends curl \
    && rm -rf /var/lib/apt/lists/*

# Upgrade pip and install build tools
RUN pip install --upgrade pip setuptools wheel

# Install only base dependencies (WITHOUT ML)
COPY requirements-base.txt ./requirements-base.txt
RUN pip install --no-cache-dir -r requirements-base.txt

# Copy application code
COPY pyproject.toml ./pyproject.toml
COPY README.md ./README.md
COPY src ./src
COPY scripts ./scripts

# Install the package itself without ML dependencies
RUN pip install --no-cache-dir --no-deps -e .

EXPOSE 8000

ENV APP_ENV=prod \
    LOG_LEVEL=INFO \
    START_EMBEDDING_WORKER=false

CMD ["uvicorn", "explanation_service.app:create_app", "--factory", "--host", "0.0.0.0", "--port", "8000"]
```

**Примечание**: `requirements-base.txt` уже создан в текущей оптимизации (23.12.2024).

### 5. Создание Dockerfile для Worker

**Создать `backend/python-generator/Dockerfile.worker`:**

```dockerfile
FROM python:3.11-slim

ENV PYTHONDONTWRITEBYTECODE=1 \
    PYTHONUNBUFFERED=1

WORKDIR /app

RUN apt-get update \
    && apt-get install -y --no-install-recommends build-essential git curl \
    && rm -rf /var/lib/apt/lists/*

# Upgrade pip and install build tools
RUN pip install --upgrade pip setuptools wheel

# Layer 1: Install base dependencies
COPY requirements-base.txt ./requirements-base.txt
RUN pip install --no-cache-dir -r requirements-base.txt

# Layer 2: Install ML dependencies (cached unless requirements-ml.txt changes)
COPY requirements-ml.txt ./requirements-ml.txt
RUN pip install --no-cache-dir --prefer-binary -r requirements-ml.txt

# Layer 3: Copy application code
COPY pyproject.toml ./pyproject.toml
COPY README.md ./README.md
COPY src ./src
COPY scripts ./scripts

# Install the package with ML dependencies
RUN pip install --no-cache-dir -e ".[worker]"

ENV APP_ENV=prod \
    LOG_LEVEL=INFO

CMD ["explanation-worker"]
```

**Примечание**: `requirements-ml.txt` уже создан в текущей оптимизации (23.12.2024).

### 6. Обновление docker-compose.yml

**Обновить `docker-compose.yml`:**

```yaml
  # Python Explanation Builder API (БЕЗ ML библиотек)
  python-generator-api:
    build:
      context: ./backend/python-generator
      dockerfile: Dockerfile.api
    container_name: trainingground-python-generator-api
    ports:
      - "8000:8000"
    environment:
      APP_ENV: ${APP_ENV:-dev}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      MONGODB_URI: ${MONGODB_URI:-mongodb://admin:changeme@mongodb:27017/trainingground?authSource=admin}
      MONGODB_DB: ${MONGODB_DB:-trainingground}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      QDRANT_URL: ${QDRANT_URL:-http://qdrant:6333}
      QDRANT_API_KEY: ${QDRANT_API_KEY:-}
      YANDEXGPT_API_KEY: ${YANDEXGPT_API_KEY:-}
      YANDEXGPT_FOLDER_ID: ${YANDEXGPT_FOLDER_ID:-}
      YANDEXGPT_MODEL: ${YANDEXGPT_MODEL:-yandexgpt-lite}
      YANDEXGPT_TEMPERATURE: ${YANDEXGPT_TEMPERATURE:-0.2}
      YANDEXGPT_MAX_TOKENS: ${YANDEXGPT_MAX_TOKENS:-700}
      YANDEXGPT_TIMEOUT_SECONDS: ${YANDEXGPT_TIMEOUT_SECONDS:-2.0}
      YANDEXGPT_SYSTEM_PROMPT: ${YANDEXGPT_SYSTEM_PROMPT:-}
      EXPLANATION_YANDEXGPT_ENABLED: ${EXPLANATION_YANDEXGPT_ENABLED:-1}
      START_EMBEDDING_WORKER: "false"  # НЕ запускать worker в API
    depends_on:
      - mongodb
      - redis
      - qdrant
    networks:
      - trainingground-network
    healthcheck:
      test: ["CMD", "curl", "-f", "http://localhost:8000/health"]
      interval: 30s
      timeout: 5s
      retries: 3
      start_period: 10s

  # Python Embedding Worker (С ML библиотеками)
  python-generator-worker:
    build:
      context: ./backend/python-generator
      dockerfile: Dockerfile.worker
    container_name: trainingground-python-generator-worker
    environment:
      APP_ENV: ${APP_ENV:-dev}
      LOG_LEVEL: ${LOG_LEVEL:-INFO}
      MONGODB_URI: ${MONGODB_URI:-mongodb://admin:changeme@mongodb:27017/trainingground?authSource=admin}
      MONGODB_DB: ${MONGODB_DB:-trainingground}
      REDIS_URL: ${REDIS_URL:-redis://redis:6379/0}
      REDIS_STREAM_NAME: ${REDIS_STREAM_NAME:-content:changes}
      REDIS_STREAM_GROUP: ${REDIS_STREAM_GROUP:-embedding-workers}
      REDIS_CONSUMER_NAME: ${HOSTNAME:-worker-1}
      QDRANT_URL: ${QDRANT_URL:-http://qdrant:6333}
      QDRANT_API_KEY: ${QDRANT_API_KEY:-}
      EMBEDDING_MODEL_NAME: ${EMBEDDING_MODEL_NAME:-sentence-transformers/paraphrase-multilingual-MiniLM-L12-v2}
      FASTTEXT_MODEL_PATH: ${FASTTEXT_MODEL_PATH:-}
    depends_on:
      - mongodb
      - redis
      - qdrant
    networks:
      - trainingground-network
    # Можно масштабировать: docker-compose up -d --scale python-generator-worker=3
    deploy:
      replicas: 1
      resources:
        limits:
          memory: 2G  # ML модели требуют больше памяти
        reservations:
          memory: 1G

  # DEPRECATED: старый монолитный сервис (удалить после миграции)
  # python-generator:
  #   build:
  #     context: ./backend/python-generator
  #     dockerfile: Dockerfile
  #   ...
```

### 7. Обновление Prometheus конфигурации

**Обновить `infra/prometheus/prometheus.yml`:**

```yaml
scrape_configs:
  # Python Generator API метрики
  - job_name: 'python-generator-api'
    static_configs:
      - targets: ['python-generator-api:8000']
    metrics_path: '/metrics'

  # Python Generator Worker метрики (если экспортируются)
  - job_name: 'python-generator-worker'
    static_configs:
      - targets: ['python-generator-worker:8000']  # Если worker экспортирует метрики
    metrics_path: '/metrics'
```

### 8. Создание скрипта миграции

**Создать `infra/scripts/migrate_to_split_services.sh`:**

```bash
#!/usr/bin/env bash
set -euo pipefail

echo "Миграция python-generator на split architecture..."

# 1. Остановить старый монолитный сервис
echo "[1/5] Остановка старого python-generator..."
docker-compose stop python-generator || true
docker-compose rm -f python-generator || true

# 2. Собрать новые образы
echo "[2/5] Сборка python-generator-api (БЕЗ ML)..."
docker-compose build python-generator-api

echo "[3/5] Сборка python-generator-worker (С ML)..."
docker-compose build python-generator-worker

# 3. Запустить новые сервисы
echo "[4/5] Запуск новых сервисов..."
docker-compose up -d python-generator-api python-generator-worker

# 4. Проверить health
echo "[5/5] Проверка health check..."
sleep 5
curl -f http://localhost:8000/health || {
  echo "ERROR: API health check failed"
  docker-compose logs python-generator-api
  exit 1
}

echo "✅ Миграция завершена успешно!"
echo "Проверьте логи:"
echo "  docker-compose logs -f python-generator-api"
echo "  docker-compose logs -f python-generator-worker"
```

### 9. Документация

**Создать `docs/python-generator-architecture.md`:**

- Диаграмма новой архитектуры
- Объяснение разделения API/Worker
- Инструкции по масштабированию worker (`--scale`)
- Мониторинг метрик для обоих сервисов
- Troubleshooting (worker OOM, Redis Stream backlog)

**Обновить `docs/explanation-service.md`:**

- Добавить раздел "Architecture: API and Worker separation"
- Описать переменную окружения `START_EMBEDDING_WORKER`
- Примеры запуска только API или только worker

**Обновить `docs/dev-setup.md`:**

- Инструкции по сборке отдельных сервисов
- Команды для локальной разработки API без worker
- Отладка worker через logs

## Ожидаемые артефакты

### Код
- ✅ `backend/python-generator/pyproject.toml` с optional-dependencies `[worker]`
- ✅ `backend/python-generator/src/explanation_service/cli/api.py` (новый entrypoint)
- ✅ `backend/python-generator/app.py` с условным запуском worker
- ✅ `backend/python-generator/Dockerfile.api` (БЕЗ ML)
- ✅ `backend/python-generator/Dockerfile.worker` (С ML)
- ⚠️ `backend/python-generator/Dockerfile` (оставить как deprecated для обратной совместимости)

### Инфраструктура
- ✅ Обновлённый `docker-compose.yml` с двумя сервисами
- ✅ Обновлённый `infra/prometheus/prometheus.yml`
- ✅ Скрипт миграции `infra/scripts/migrate_to_split_services.sh`
- ✅ Обновлённый `.env.example` с новыми переменными

### Документация
- ✅ `docs/python-generator-architecture.md` (новый файл)
- ✅ Обновлённый `docs/explanation-service.md`
- ✅ Обновлённый `docs/dev-setup.md`

## Чек-лист выполнения

### Подготовка
- [ ] Создать ветку `feature/td-02-split-python-generator`
- [ ] Проверить текущую функциональность (запустить тесты A3)

### Разделение зависимостей
- [ ] Обновить `pyproject.toml` с `[project.optional-dependencies]`
- [ ] Создать `cli/api.py` entrypoint
- [ ] Обновить `app.py` с `START_EMBEDDING_WORKER`
- [ ] Протестировать локально: `python -m explanation_service.cli.api`

### Docker образы
- [ ] Создать `Dockerfile.api` (БЕЗ ML)
- [ ] Создать `Dockerfile.worker` (С ML)
- [ ] Собрать оба образа: `docker-compose build`
- [ ] Проверить размеры образов (API ~150 MB, Worker ~850 MB)

### Docker Compose
- [ ] Обновить `docker-compose.yml` с двумя сервисами
- [ ] Добавить переменные окружения для обоих сервисов
- [ ] Настроить health checks
- [ ] Протестировать: `docker-compose up -d python-generator-api python-generator-worker`

### Тестирование
- [ ] **API health check**: `curl http://localhost:8000/health` → 200 OK
- [ ] **API endpoint**: `POST /v1/explanations` с YandexGPT → успешный ответ
- [ ] **Worker logs**: проверить, что worker читает Redis Stream
- [ ] **Embedding flow**: создать template → проверить Qdrant содержит embeddings
- [ ] **Масштабирование**: `docker-compose up -d --scale python-generator-worker=3`
- [ ] **Время сборки**: измерить время сборки API (должно быть ~2 минуты)

### Мониторинг и метрики
- [ ] Обновить `prometheus.yml` с новыми job_name
- [ ] Проверить Prometheus scrape таргеты (оба UP)
- [ ] Проверить метрики в Grafana (если дашборды созданы)

### Документация
- [ ] Создать `docs/python-generator-architecture.md`
- [ ] Обновить `docs/explanation-service.md`
- [ ] Обновить `docs/dev-setup.md`
- [ ] Создать скрипт миграции `migrate_to_split_services.sh`

### Финализация
- [ ] Запустить pre-commit тесты (pytest, ruff)
- [ ] Создать Pull Request с описанием изменений
- [ ] Code review
- [ ] Merge в main
- [ ] Удалить старый монолитный сервис из docker-compose.yml

## Тестирование

### Функциональное тестирование
1. **API без worker**:
   - Запустить только `python-generator-api`
   - Проверить `/v1/explanations` работает
   - Проверить `/v1/rag/search` работает
   - Worker не должен быть в логах

2. **Worker автономно**:
   - Запустить только `python-generator-worker`
   - Создать событие в Redis Stream вручную
   - Проверить, что worker обработал событие
   - Проверить Qdrant содержит embeddings

3. **Интеграционный тест**:
   - Запустить оба сервиса
   - Создать template в MongoDB
   - Проверить событие попало в Redis Stream
   - Проверить worker обработал событие
   - Проверить Qdrant содержит embeddings
   - Проверить RAG search находит template

### Производительность
1. **Время сборки**:
   - Измерить `docker-compose build python-generator-api` (ожидается ~2 минуты)
   - Измерить `docker-compose build python-generator-worker` (ожидается ~14 минут первый раз)
   - Изменить код в `src/` → пересобрать API (ожидается ~20 секунд с кэшем)

2. **Размер образов**:
   - API: ~150-200 MB
   - Worker: ~800-900 MB

3. **Потребление ресурсов**:
   - API: ~100-200 MB RAM
   - Worker: ~1-2 GB RAM (из-за ML моделей)

### Масштабирование
1. **Множественные worker**:
   ```bash
   docker-compose up -d --scale python-generator-worker=3
   ```
   - Проверить 3 worker контейнера запущены
   - Проверить все подключены к Redis Stream consumer group
   - Создать 100 events в Redis Stream
   - Проверить workload распределён между workers

2. **Worker restart без downtime API**:
   ```bash
   docker-compose restart python-generator-worker
   ```
   - Проверить API продолжает работать
   - Проверить `/v1/explanations` доступен

## Приоритизация

### P0 (Must-have)
1. Разделение зависимостей в `pyproject.toml`
2. Создание `Dockerfile.api` и `Dockerfile.worker`
3. Обновление `docker-compose.yml`
4. Рефакторинг `app.py` с `START_EMBEDDING_WORKER`

### P1 (Should-have)
5. Создание `cli/api.py` entrypoint
6. Обновление Prometheus конфигурации
7. Документация архитектуры

### P2 (Nice-to-have)
8. Скрипт автоматической миграции
9. Grafana дашборды для обоих сервисов
10. Health check для worker (опционально)

## Зависимости
- **Требует**: A3 (Python Explanation Builder) выполнено ✅
- **Блокирует**: нет (техдолг, не блокирует новые фичи)
- **Связано**: TD-01 (мониторинг), TD-03 (если есть оптимизации инфраструктуры)

## Оценка времени
- **Разделение зависимостей**: 2 часа
- **Создание Dockerfile.api/worker**: 2 часа
- **Рефакторинг app.py**: 1 час
- **Обновление docker-compose.yml**: 1 час
- **Тестирование**: 3 часа (функциональное + интеграционное)
- **Документация**: 2 часа

**Итого**: ~11 часов (≈1.5 рабочих дня для 1 разработчика)

## Успешное завершение

Задача считается выполненной, когда:
1. ✅ Существуют два независимых Docker образа: `python-generator-api` и `python-generator-worker`
2. ✅ API образ собирается за **≤3 минуты** без ML зависимостей
3. ✅ Worker образ содержит все ML библиотеки и собирается за ~14 минут
4. ✅ Оба сервиса работают в `docker-compose` с разделённой конфигурацией
5. ✅ При изменении кода в `src/` API пересобирается за **≤30 секунд** (с кэшем)
6. ✅ Worker может быть масштабирован через `--scale` без изменения API
7. ✅ Все тесты A3 проходят с новой архитектурой
8. ✅ Документация обновлена и описывает новую архитектуру
9. ✅ Prometheus собирает метрики с обоих сервисов
10. ✅ Старый монолитный `python-generator` удалён из `docker-compose.yml`

После выполнения TD-02 разработка и CI/CD для Python сервисов станет **в 7 раз быстрее** (14 минут → 2 минуты для изменений API).

## Откат (Rollback Plan)

Если миграция вызывает проблемы:

1. **Быстрый откат**:
   ```bash
   # Вернуться к старому монолитному сервису
   docker-compose stop python-generator-api python-generator-worker
   docker-compose up -d python-generator  # Старый монолитный сервис
   ```

2. **Проблемы совместимости**:
   - Оставить оба варианта (старый + новый) в `docker-compose.yml` с разными profiles
   - Profile `legacy`: старый монолитный сервис
   - Profile `split` (default): новая архитектура

3. **Переходный период**:
   - Держать оба варианта в production 1-2 недели
   - Сравнить метрики производительности/стабильности
   - Окончательно удалить монолитный сервис после подтверждения

**Критерии для отката**:
- API error rate >1% (сравнение с baseline)
- Worker не обрабатывает events >5 минут
- Embeddings не попадают в Qdrant
- Критические баги в production

## Примечания

- Текущая оптимизация (23.12.2024) уже создала `requirements-base.txt` и `requirements-ml.txt`, что упрощает реализацию TD-02
- Redis Stream consumer group уже настроен в A3, поэтому масштабирование worker будет работать автоматически
- Worker можно запускать в Kubernetes с HPA (Horizontal Pod Autoscaler) на основе размера Redis Stream backlog
- Для дальнейшей оптимизации можно рассмотреть использование готового ML образа как base image (например, `huggingface/transformers-pytorch-cpu`)
