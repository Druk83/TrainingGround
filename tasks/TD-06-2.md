# TD-06-2 — Интеграция YandexGPT и автоматизированное обогащение контента

## Контекст
Фаза TD-06-1 построила интерфейс и API для ручного контроля генерации (форма, история запусков, CRUD задач, логирование). Однако сами задания по-прежнему создаются из статических шаблонов — TemplateGenerator просто подставляет заранее заданные слова. Контент-команда всё ещё не может масштабно пополнять банк вопросов, потому что нет автоматической генерации через ИИ и «обогащённые» варианты не попадают в учебные курсы. TD-06-2 должна закрыть этот разрыв.

## Цели
1. Подключить YandexGPT в python-generator, чтобы формировать новые тексты на основе шаблонов.
2. Дать контент-админу инструменты настройки промпта и параметров LLM в админке.
3. Обеспечить постобработку/валидацию ответов LLM и логирование всех вызовов.
4. Научить backend и фронт различать источники вариантов (LLM vs TemplateEngine) и выдавать ученикам только утверждённые LLM-вопросы.
5. Обеспечить мониторинг, тесты и документацию по новому пайплайну.

## Функциональные требования

### 1. Python-generator: клиент YandexGPT
- [ ] Реализовать модуль `yandexgpt_client`:
  - параметры конфигурации: `YANDEXGPT_API_URL`, `YANDEXGPT_MODEL`, `YANDEXGPT_API_KEY`, `YANDEXGPT_TIMEOUT_MS`, `YANDEXGPT_RETRY_COUNT`, `YANDEXGPT_TEMPERATURE`, `YANDEXGPT_TOP_K`;
  - метод `generate(prompt: str, settings: LlmSettings) -> LlmResponse`, с ретраями и логированием `request_id`;
  - обработка HTTP/JSON ошибок с детальными сообщениями.
- [ ] Для каждого шаблона хранить `llm_prompt` и `llm_settings` (temperature, max_tokens, доп. инструкции).
- [ ] При генерации:
  - если шаблон включает LLM-параметры, формировать промпт, подставляя данные (`{{topic_name}}`, примеры, правильные ответы, формат таблиц);
  - вызывать YandexGPT, получать 1..N вариантов в структуре: `[{text, correct_answer, options[], notes}]`.
- [ ] Постобработка:
  - очистка текста (trim, проверка длины, запрещённые слова);
  - извлечение/валидация правильного ответа (в том числе если LLM возвращает JSON);
  - автоматическая расстановка `status = pending_review` до утверждения.
- [ ] Фолбэк: если LLM недоступен или дал невалидный ответ, использовать TemplateEngine; сохранять причину в run.
- [ ] Сохранять `prompt`, `raw_response`, `model_name`, `latency_ms` в `template_enrichment_tasks`.

### 2. Backend (Rust): модель шаблона и API
- [ ] Расширить `TemplateDocument` и API:
  - `metadata.llm_prompt`, `metadata.llm_variables`, `metadata.llm_settings`;
  - `metadata.enrichment_mode = template_engine | yandexgpt | hybrid`.
- [ ] Новые admin endpoints:
  - `GET/PUT /admin/templates/:id/llm-settings` — получить/обновить промпт и параметры (с валидацией placeholders);
  - `POST /admin/templates/:id/llm-preview` — быстрый тест промпта (возвращает 1 вариант, не сохраняет).
- [ ] `TemplateEnrichmentRequest` дополняется полем `mode` и `llm_override` (например, временной temperature).
- [ ] `TemplateEnrichmentRunSummary` и `TemplateEnrichmentTaskView` должны указывать `source` (`llm`/`template_engine`) и `model`.
- [ ] SessionService: добавить опцию брать готовые approved-вопросы из `template_enrichment_tasks` перед генерацией "на лету" (например, когда поле `metadata.use_enriched_pool = true`), с fallback на живую генерацию.

### 3. Frontend (admin console)
- [ ] Раздел настроек шаблона:
  - форма редактирования промпта (textarea с подсветкой placeholders);
  - поля для temperature, max_tokens, top_k, `allow_reuse` и т.п.;
  - превью плейсхолдеров и допустимых переменных.
- [ ] Во вкладке «Обогащение»:
  - добавить селектор режима генерации (`TemplateEngine`, `YandexGPT`, `Hybrid`);
  - выводить источник у каждой задачи (badge «LLM», hover-подсказка с моделью/тем, ссылкой на промпт);
  - кнопка «Показать промпт/ответ» (модалка с сырым текстом).
- [ ] Для pipeline «LLM -> проверка -> ученики» добавить статус `pending_review`, `approved`, `rejected` и UI для утверждения.

### 4. Post-processing / QA
- [ ] Реализовать модуль проверки качества:
  - список запрещённых слов/regex (конфиг через `.env`);
  - проверка формата (каноничные пробелы, отсутствие HTML, запрет на слишком длинные ответы);
  - возможность задать custom-валидаторы (например, проверка орфограмм).
- [ ] Авто-пометка `status = rejected` при нарушении правил и запись причины в run/task.
- [ ] Unit-тесты на генерацию/валидаторы.

### 5. Выдача ученикам
- [ ] В SessionService:
  - при старте сессии проверять, есть ли approved-вопросы в `template_enrichment_tasks` для уровня;
  - поддержка стратегии «mix»: N вопросов из пула, остальные — живые;
  - флаг `metadata.use_enriched_pool` и настройки «минимум готовых вопросов».
- [ ] Логировать, какие вопросы студент получил (идентификатор enriched-task, модель, версия).

### 6. Мониторинг и DevOps
- [ ] Метрики (Prometheus):
  - `llm_requests_total`, `llm_errors_total`, `llm_latency_seconds`;
  - количество approved/rejected задач;
  - доля задач, выданных ученикам из LLM-пула.
- [ ] Алёрты: превышение ошибок LLM, рост rejected > X%.
- [ ] Обновление документации: `docs/content-admin-guide.md` (работа с промптом, статусами, утверждением вопросов), `docs/devops/runbooks.md` (как диагностировать ошибки YandexGPT).

## Критерии приёмки
1. Контент-админ может настроить промпт, запустить YandexGPT-генерацию и увидеть, что задачи пришли с источником «LLM».
2. При некорректном ответе (или недоступности LLM) run завершается с ошибкой, но UI показывает причину; fallback работает.
3. После утверждения задач (`approved`) ученики получают их в курсе (видно по логам и UI).
4. Все вызовы YandexGPT логируются с `request_id`, latency и моделью.
5. Метрики в Grafana показывают уровень ошибок и распределение источников.
6. Документация описывает весь процесс.
